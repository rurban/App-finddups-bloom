#!/usr/bin/perl
# Reini Urban rurban@cpanel.net 2014
# This does not qualify for the regular dfw contest entry, but is more practical,
# more in the spirit of a coreutil and faster.
package App::finddups::bloom;

use strict;
our $VERSION = '0.01';

# local::lib hack, dfw-specific only
# push @INC, "perl5/lib/perl5:perl5/lib/perl5/x86_64-linux-gnu-thread-multi";

=head1 NAME

App::finddups::bloom

=head1 SYNOPSIS

    finddups-bloom      # acting on /dedup

    finddups-bloom /dir
    finddups-bloom /dir | xargs rm        # printable filenames without spaces only

    finddups-bloom -0 /dir | xargs -0 rm  # quote unprintable chars and filenames containing space

=head1 DESCRIPTION

Finds and prints most file duplicates under the given directory via bloom filters.
Ignores symlinks and hardlinks.

=cut

use File::Util;
use Bloom::Faster;
use Digest::CRC;
use Getopt::Long;

my %opt;
GetOptions (\%opt,
            "0|print0",
            "help|h",
            "verbose|v",
            "maxcrc=i",
            "bloomsize=i",
            "bloomsize2=i",
            "bloomerr=s",
  );
if ($opt{help}) {
  require Pod::Usage;
  Pod::Usage->import('pod2usage');
  pod2usage(0);
}
if ($opt{0}) {
  require B;
}

my $root = shift || "/dedup";
my $maxcrc = $opt{maxcrc} || 1_000_000;
my $bloomsize = $opt{bloomsize} || 100_000;
my $bloomsize2 = $opt{bloomsize2} || 2000;
my $bloomerr = $opt{bloomerr} || 0.01;

my $size = new Bloom::Faster({n => $bloomsize, e => $bloomerr});  # expected elements + error rate (not using options yet)
my $hash = new Bloom::Faster({n => $bloomsize2, e => $bloomerr}); # less expected same-size entries
my $crc = Digest::CRC->new(type=>"crc64");
my $s; # global crc buffer

print "# finding most likely duplicates in $root\n" if $opt{verbose};

sub wanted {
  return if !-f $_ or -l $_ ;  # skip symlinks and non-files
  return if (stat($_))[3] > 1; # also skip hardlinks not using a inode hash, the fs already stores nlinks
  if ($size->add(-s _)) {      # only compare same filesizes
    my $c;
    open my $f,'<',$_;
    if (-s _ < $maxcrc) {
      $c = $crc->addfile($f);
    } else {
      sysread $f, $s, $maxcrc; # only check the first 1 million bytes
      $c = $crc->add($s);
    }
    if ($hash->add($c)) {
      if ($opt{0}) {
        print B::cstring($File::Find::name)."\000\n";
      } else {
        print $File::Find::name."\n";
      }
    }
    close $f;
  }
}

find(\&wanted, $root) unless caller;

END {
  if ($opt{verbose}) {
    print "\n#bloom filter stats: ", $size->key_count, " size keys, ", $size->capacity, " size capacity\n";
    print   "#                    ", $hash->key_count, " hash keys, ", $hash->capacity, " hash capacity\n";
  }
}

=head1 OPTIONS

--print0 | -0 quote unprintable filename characters for xargs -0

--bloomsize expected number of files, defaults to 1_000_000;

--bloomsize2 expected number of duplicates, defaults to 2000;

--bloomerr wanted error rate, defaults to 0.01 i.e. 1%

--maxcrc  maximal file content size which is checked

--verbose prints header and footer prefixed with #

--help prints short usage

=head1 INTERNALS

This code doesn't follow the contest rules, as it doesn't store the source links. 
It only checks and prints duplicates, and therefore can use fast and memory efficient
Bloom filters.

The default accuracy is 99.99% for 1 million files which should satisfy all
practical purposes. And if you care for more run it a second time, combined with rm.
It is fast because it uses bloom filters not hashes, hence the 99.99%
and not 100% and it doesn't print the source for the duplicates, only the
duplicates.

To remove the duplicates apply C<rm> to the list of entries, such as

    finddups-bloom -0 | xargs -0 rm

It needs between 20MB and 55MB memory, compared to 333MB with the reference perl5
code using perl hashes.

cloc: 57

$ perlcritic finddups-bloom
finddups-bloom source OK

=head1 LICENSE

Written and copyright 2014 by Reini Urban rurban@cpanel.net
for the Dallas/Fort Worth Perl Mongers dfw dedup contest 2014
http://dfw.pm.org/

This program is free software; you can redistribute it and/or modify
it under the terms of Perl5, which is either:

a) the GNU General Public License as published by the Free
   Software Foundation; either version 1, or (at your option) any
   later version, or

b) the "Artistic License" which comes with this kit.

