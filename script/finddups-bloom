#!/usr/bin/perl
# Reini Urban rurban@cpanel.net 2014
# This does not qualify for the regular dfw contest entry, but is more practical,
# more in the spirit of a coreutil and faster.
use strict;
use warnings;
use 5.008;

# local::lib hack, dfw-specific only
# push @INC, "perl5/lib/perl5:perl5/lib/perl5/x86_64-linux-gnu-thread-multi";

=head1 NAME

finddups-bloom

=head1 SYNOPSIS

    finddups-bloom      # acting on /dedup

    finddups-bloom /dir
    finddups-bloom /dir | xargs rm        # printable filenames without spaces only

    finddups-bloom -0 /dir | xargs -0 rm  # quote unprintable chars and filenames containing space

=head1 DESCRIPTION

Finds and prints most file duplicates under the given directory via bloom filters.
Ignores symlinks and hardlinks.

=cut

use Getopt::Long;
use File::Find;

my %opt;
GetOptions (\%opt,
            "0|print0",
            "help|h",
            "verbose|v",
            "maxcrc=i",
            "bloomsize=i",
            "bloomsize2=i",
            "bloomerr=s",
  );
if ($opt{'help'}) {
  require Pod::Usage;
  Pod::Usage->import('pod2usage');
  pod2usage(0);
}

my $root = shift || "/dedup";
my $maxcrc = $opt{'maxcrc'} || 1_000_000;
my $bloomsize = $opt{'bloomsize'} || 100_000;
my $bloomsize2 = $opt{'bloomsize2'} || 2000;
my $bloomerr = $opt{'bloomerr'} || 0.01;

use App::finddups::bloom;

App::finddups::bloom::options(%opt);
print "# finding most likely duplicates in $root\n" if $opt{'verbose'};

File::Find::find(\&App::finddups::bloom::wanted, $root) unless caller;

=head1 OPTIONS

--print0 | -0 quote unprintable filename characters for xargs -0

--bloomsize expected number of files, defaults to 1_000_000;

--bloomsize2 expected number of duplicates, defaults to 2000;

--bloomerr wanted error rate, defaults to 0.01 i.e. 1%

--maxcrc  maximal file content size which is checked

--verbose prints header and footer prefixed with #

--help prints short usage

=head1 INTERNALS

This code doesn't follow the contest rules, as it doesn't store the source links. 
It only checks and prints duplicates, and therefore can use fast and memory efficient
Bloom filters.

The default accuracy is 99.99% for 1 million files which should satisfy all
practical purposes. And if you care for more run it a second time, combined with rm.
It is fast because it uses bloom filters not hashes, hence the 99.99%
and not 100% and it doesn't print the source for the duplicates, only the
duplicates.

To remove the duplicates apply C<rm> to the list of entries, such as

    finddups-bloom -0 | xargs -0 rm

It needs between 20MB and 55MB memory, compared to 333MB with the reference perl5
code using perl hashes.

cloc: 57

$ perlcritic finddups-bloom
finddups-bloom source OK

=head1 LICENSE

Written and copyright 2014 by Reini Urban rurban@cpanel.net
for the Dallas/Fort Worth Perl Mongers dfw dedup contest 2014
http://dfw.pm.org/

This program is free software; you can redistribute it and/or modify
it under the terms of Perl5, which is either:

a) the GNU General Public License as published by the Free
   Software Foundation; either version 1, or (at your option) any
   later version, or

b) the "Artistic License" which comes with this kit.

print "# finding most likely duplicates in $root\n" if $opt{verbose};

